- paper_title: "X-vectors: Robust DNN Embeddings for Speaker Recognition"
  author_list: David Snyder, Daniel Garcia-Romero, Gregory Sell, Daniel Povey, Sanjeev Khudanpur
  journal: IEEE ICASSP 2018
  abstract_text: In this paper, we use data augmentation to improve performance of deep neural network (DNN) embeddings for speaker recognition. The DNN, which is trained to discriminate between speakers, maps variable-length utterances to fixed-dimensional embeddings that we call x-vectors. Prior studies have found that embeddings leverage large-scale training datasets better than i-vectors. However, it can be challenging to collect substantial quantities of labeled data for training. We use data augmentation, consisting of added noise and reverberation, as an inexpensive method to multiply the amount of training data and improve robustness. The x-vectors are compared with i-vector baselines on Speakers in the Wild and NIST SRE 2016 Cantonese. We find that while augmentation is beneficial in the PLDA classifier, it is not helpful in the i-vector extractor. However, the x-vector DNN effectively exploits data augmentation, due to its supervised training. As a result, the x-vectors achieve superior performance on the evaluation datasets.
  pdf_link: http://www.danielpovey.com/files/2018_icassp_xvectors.pdf
  code_link: https://github.com/kaldi-asr/kaldi/tree/master/egs/sre16/v2
  slides_link:
  poster_link:
  video_link:

- paper_title: Compressed time delay neural network for small-footprint keyword spotting
  author_list: Ming Sun, David Snyder, Yixin Gao, Varun Nagaraja, Mike Rodehorst, Nikko Strom Panchapagesan, Spyros Matsoukas, Shiv Vitaladevuni
  abstract_text: In this paper we investigate a time delay neural network (TDNN) for a keyword spotting task that requires low CPU, memory and latency. The TDNN is trained with transfer learning and multi-task learning. Temporal subsampling enabled by the time delay architecture reduces computational complexity. We propose to apply singular value decomposition (SVD) to further reduce TDNN complexity. This allows us to first train a larger full-rank TDNN model which is not limited by CPU/memory constraints. The larger TDNN usually achieves better performance. Afterwards, its size can be compressed by SVD to meet the budget requirements. Hidden Markov models (HMM) are used in conjunction with the networks to perform keyword detection and performance is measured in terms of area under the curve (AUC) for detection error tradeoff (DET) curves. Our experimental results on a large in-house far-field corpus show that the full-rank TDNN achieves a 19.7% DET AUC reduction compared to a similar-size deep neural network (DNN) baseline. If we train a larger size full-rank TDNN first and then reduce it via SVD to the comparable size of the DNN, we obtain a 37.6% reduction in DET AUC compared to the DNN baseline.
  pdf_link: https://pdfs.semanticscholar.org/8eda/5fa7103406403a14342336c684b666dfdfc8.pdf
  journal: INTERSPEECH 2017
  code_link:
  slides_link:
  poster_link:
  video_link:

- paper_title: Deep Neural Network Embeddings for Text-Independent Speaker Verification
  author_list: David Snyder, Daniel Garcia-Romero, Daniel Povey, Sanjeev Khudanpur
  abstract_text: This paper investigates replacing i-vectors for text-independent speaker verification with embeddings extracted from a feedforward deep neural network. Long-term speaker characteristics are captured in the network by a temporal pooling layer that aggregates over the input speech. This enables the network to be trained to discriminate between speakers from variable-length speech segments. After training, utterances are mapped directly to fixed-dimensional speaker embeddings and pairs of embeddings are scored using a PLDA-based backend. We compare performance with a traditional i-vector baseline on NIST SRE 2010 and 2016. We find that the embeddings outperform i-vectors for short speech segments and are competitive on long duration test conditions. Moreover, the two representations are complementary, and their fusion improves on the baseline at all operating points. Similar systems have recently shown promising results when trained on very large proprietary datasets, but to the best of our knowledge, these are the best results reported for speaker-discriminative neural networks when trained and tested on publicly available corpora.
  journal: INTERSPEECH 2017
  pdf_link: http://www.danielpovey.com/files/2017_interspeech_embeddings.pdf
  code_link: 
  slides_link:
  poster_link:
  video_link:

- paper_title: Speaker Diarization using Deep Neural Network Embeddings
  author_list: Daniel Garcia-Romero, David Snyder, Gregory Sell, Daniel Povey, Alan McCree
  abstract_text: Speaker diarization is an important front-end for many speech technologies in the presence of multiple speakers, but current methods that employ i-vector clustering for short segments of speech are potentially too cumbersome and costly for the front-end role. In this work, we propose an alternative approach for learning representations via deep neural networks to remove the i-vector extraction process from the pipeline entirely. The proposed architecture simultaneously learns a fixed-dimensional embedding for acoustic segments of variable length and a scoring function for measuring the likelihood that the segments originated from the same or different speakers. Through tests on the CALLHOME conversational telephone speech corpus, we demonstrate that, in addition to streamlining the diarization architecture, the proposed system matches or exceeds the performance of state-of-the-art baselines. We also show that, though this approach does not respond as well to unsupervised calibration strategies as previous systems, the incorporation of well-founded speaker priors sufficiently mitigates this shortcoming.
  journal: IEEE ICASSP 2017
  pdf_link: https://pdfs.semanticscholar.org/d3ed/25e32553e8a399bedc1850c90bf12e4e9d27.pdf
  code_link: 
  slides_link:
  poster_link:
  video_link:

- paper_title: "MUSAN: A Music, Speech, and Noise Corpus"
  author_list: David Snyder, Guoguo Chen, Daniel Povey
  abstract_text: This report introduces a new corpus of music, speech, and noise. This dataset is suitable for training models for voice activity detection (VAD) and music/speech discrimination. Our corpus is released under a flexible Creative Commons license. The dataset consists of music from several genres, speech from twelve languages, and a wide assortment of technical and non-technical noises. We demonstrate use of this corpus for music/speech discrimination on Broadcast news and VAD for speaker identification.
  journal: arXiv 2015
  pdf_link: http://arxiv.org/pdf/1510.08484v1.pdf
  database: http://www.openslr.org/17/
  code_link:
  slides_link:
  poster_link:
  video_link:


- paper_title: TIME DELAY DEEP NEURAL NETWORK-BASED UNIVERSAL BACKGROUND MODELS FOR SPEAKER RECOGNITION
  author_list: David Snyder, Daniel Garcia-Romero, Daniel Povey
  abstract_text: Recently, deep neural networks (DNN) have been incorporated into i-vector-based speaker recognition systems, where they have significantly improved state-of-the-art performance. In these systems, a DNN is used to collect sufficient statistics for i-vector extraction. In this study, the DNN is a recently developed time delay deep neural network (TDNN) that has achieved promising results in LVCSR tasks. We believe that the TDNN-based system achieves the best reported results on SRE10 and it obtains a 50% relative improvement over our GMM baseline in terms of equal error rate (EER). For some applications, the computational cost of a DNN is high. Therefore, we also investigate a lightweight alternative in which a supervised GMM is derived from the TDNN posteriors. This method maintains the speed of the traditional unsupervised-GMM, but achieves a 20% relative improvement in EER.
  journal: IEEE ASRU 2015
  pdf_link: http://danielpovey.com/files/2015_asru_tdnn_ubm.pdf
  code_link: https://github.com/kaldi-asr/kaldi/tree/master/egs/sre10
  slides_link: 
  poster_link:
  video_link:
